# ğŸ¤– Tikkles Analyst Bot v2.2 (JSON Fix & Path Unified)
import os
import time
import requests
import feedparser
import logging
from datetime import datetime
import pytz
from github import Github, GithubException
import google.generativeai as genai
from dotenv import load_dotenv
import urllib.parse
import json  # ğŸ› ï¸ Fix: Global import to prevent NameError

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("HybridBot")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
load_dotenv()

class HybridBot:
    def __init__(self):
        self.github_token = os.getenv("GH_PAT")
        self.target_repo_name = "rohbomb/rohbomb.github.io"
        self.llm_api_key = os.getenv("LLM_API_KEY")
        self.pexels_api_key = os.getenv("PEXELS_API_KEY") # ğŸ› ï¸ ë³µêµ¬: Pexels API Key ë¡œë“œ
        
        if not self.github_token:
            logger.error("âŒ GH_PAT í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            raise ValueError("GitHub Token is missing")

        # GitHub ì—°ê²°
        self.gh = Github(self.github_token)
        self.repo = self.gh.get_repo(self.target_repo_name)

        # Gemini ì„¤ì • (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
        if self.llm_api_key:
            genai.configure(api_key=self.llm_api_key)
            # ğŸš¨ Model Priority List (Fallback System)
            # 1ìˆœìœ„: gemini-2.0-flash-exp (New Experimental)
            # 2ìˆœìœ„: gemini-exp-1206 (Often Limited)
            # 3ìˆœìœ„: gemini-2.5-flash (Backup)
            self.model_candidates = ['gemini-2.0-flash-exp', 'gemini-exp-1206', 'gemini-2.5-flash']
        else:
            self.model_candidates = []
            logger.warning("âš ï¸ LLM_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. AI ìš”ì•½ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

    def fetch_news(self, keyword):
        """RSS í”¼ë“œì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        logger.info(f"ğŸ“¡ '{keyword}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        
        # í‚¤ì›Œë“œ URL ì¸ì½”ë”©
        encoded_keyword = urllib.parse.quote(keyword)
        
        # êµ¬ê¸€ ë‰´ìŠ¤ RSS (ë¯¸êµ­/ê¸€ë¡œë²Œ ìµœì‹ ìˆœ + 24ì‹œê°„ ì´ë‚´) - ì €ì‘ê¶Œ ì´ìŠˆ íšŒí”¼ ë° ì •ë³´ ì§ˆ í–¥ìƒ
        # when:1d + gl=US + hl=en-US + ceid=US:en
        rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}+when:1d&hl=en-US&gl=US&ceid=US:en"
        
        try:
            feed = feedparser.parse(rss_url)
            
            if not feed.entries:
                logger.warning(f"âš ï¸ '{keyword}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            # ì¤‘ë³µ ë°©ì§€ ë¡œì§ (processed_news.json í™œìš©)
            processed_file = "processed_news.json"
            processed_links = []
            if os.path.exists(processed_file):
                try:
                    with open(processed_file, "r", encoding="utf-8") as f:
                        processed_links = json.load(f)
                except:
                    processed_links = []
            
            for entry in feed.entries:
                if entry.link not in processed_links:
                    logger.info(f"âœ… ìƒˆ ë‰´ìŠ¤ ë°œê²¬: {entry.title}")
                    
                    # ì²˜ë¦¬ëœ ë§í¬ ì €ì¥
                    processed_links.append(entry.link)
                    # íŒŒì¼ í¬ê¸° ì¡°ì ˆ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
                    if len(processed_links) > 100:
                        processed_links = processed_links[-100:]
                        
                    with open(processed_file, "w", encoding="utf-8") as f:
                        json.dump(processed_links, f, ensure_ascii=False, indent=2)
                        
                    return {
                        'title': entry.title,
                        'link': entry.link,
                        'published': entry.published,
                        'summary': getattr(entry, 'summary', ''),
                        'keyword': keyword
                    }
            
            logger.info("â„¹ï¸ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ì²˜ë¦¬ë¨)")
            return None
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ({keyword}): {e}")
            return []

    def generate_content(self, news_item):
        """Gemini(Market Analyst)ë¥¼ ì´ìš©í•´ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… ì‘ì„± (Fallback ì ìš©)"""
        if not self.model_candidates:
            return f"AI ìš”ì•½ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì›ë¬¸ ë§í¬: {news_item['link']}"

        prompt = f"""
        ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ê¸€ë¡œë²Œ ë§¤í¬ë¡œ/ê¸°ìˆ  ë¶„ì„ê°€ 'Market Analyst Bear'ì…ë‹ˆë‹¤.
        ì•„ë˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì „ë¬¸ íˆ¬ìì ë° 3040 ì§ì¥ì¸ì„ íƒ€ê²Ÿìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë¸Œë¦¬í•‘í•´ ì£¼ì„¸ìš”.

        [ë‰´ìŠ¤ ì •ë³´]
        í‚¤ì›Œë“œ: {news_item['keyword']}
        ì œëª©(ì›ë¬¸): {news_item['title']}
        ë§í¬: {news_item['link']}
        ë‚´ìš©(ì›ë¬¸): {news_item['summary']}

        [ì‘ì„± ê·œì¹™]
        0. **Role**: ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ì‹œì¥ì˜ ìµœì‹  íŠ¸ë Œë“œë¥¼ í•œêµ­ íˆ¬ììì—ê²Œ ì†Œê°œí•˜ëŠ” 'Market Analyst Bear'ì…ë‹ˆë‹¤.
           - ì˜ë¬¸ ê¸°ì‚¬ë¥¼ ì½ê³  ì™„ë²½í•œ **í•œêµ­ì–´(Korean)**ë¡œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        1. **Tone & Style**:
           - **Professional**: ì •ì¤‘í•˜ë˜ ë‹¨í˜¸í•œ ì „ë¬¸ê°€ì  ì–´ì¡°.
           - **Insightful (ë§¤ìš° ì¤‘ìš”)**: ë‹¨ìˆœ ë²ˆì—­ì´ë‚˜ ìš”ì•½ì´ ì•„ë‹™ë‹ˆë‹¤. ì´ ë‰´ìŠ¤ê°€ í•œêµ­ ì‹œì¥ì´ë‚˜ ê°œì¸ íˆ¬ììì—ê²Œ ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€ **'í•´ì„'**í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”.
           - **Natural Localization**: ë²ˆì—­ê¸°(DeepL/Google)ë¥¼ ëŒë¦° ë“¯í•œ ì§ì—­ì²´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. í•œêµ­ íˆ¬ììë“¤ì´ ìˆ ìˆ  ì½ì„ ìˆ˜ ìˆëŠ” **ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ìš©ì–´ì™€ ì—…ê³„ ì „ë¬¸ ìš©ì–´**ë¥¼ ì ì ˆíˆ ì„ì–´ì„œ ì‘ì„±í•˜ì„¸ìš”.
           - **Teaser Strategy**: ì›ë¬¸ì˜ ëª¨ë“  ë‚´ìš©ì„ ë‹¤ ë§í•´ì£¼ì§€ ë§ˆì„¸ìš”. ë…ìê°€ 'ì›ë¬¸ ë§í¬'ë¥¼ í´ë¦­í•˜ê³  ì‹¶ê²Œë” í•µì‹¬ë§Œ ìš”ì•½(Curate)í•˜ì„¸ìš”. (ì €ì‘ê¶Œ ë³´í˜¸ ëª©ì )

        2. **Output Format (Markdown)**:
           - **Title**: ì›ë¬¸ ì œëª©ì„ ë²ˆì—­í•˜ì§€ ë§ê³ , í•œêµ­ ë…ìê°€ í´ë¦­í•  ë§Œí•œ 'ë§¤ë ¥ì ì¸ ì¸ì‚¬ì´íŠ¸í˜• ì œëª©'ì„ ìƒˆë¡œ ì§€ìœ¼ì„¸ìš”.
           - **ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€**: ì œëª©ê³¼ ë³¸ë¬¸ì— ì´ëª¨í‹°ì½˜(â¡ï¸, âœ… ë“±) ì ˆëŒ€ ê¸ˆì§€.
           - **Key Facts (3ì¤„ ìš”ì•½)**
             - ì›ë¬¸ì˜ í•µì‹¬ íŒ©íŠ¸ 3ê°€ì§€ë¥¼ ê±´ì¡°í•˜ê²Œ ìš”ì•½. 
             - (ì¶œì²˜: [ì›ë¬¸ ë§¤ì²´ëª…]) í˜•ì‹ìœ¼ë¡œ ë¬¸ì¥ ëì— ì¶œì²˜ ì•”ì‹œ.
           - **Analyst's Insight (í•µì‹¬)**
             - ì´ê³³ì˜ ë¶„ëŸ‰ì„ Key Factsë³´ë‹¤ 2ë°° ì´ìƒ ê¸¸ê²Œ ì‘ì„±í•˜ì„¸ìš”.
             - "ì´ ë‰´ìŠ¤ëŠ” ~ë¼ëŠ” ì ì—ì„œ ì¤‘ìš”í•©ë‹ˆë‹¤.", "ì•ìœ¼ë¡œ ~ë¶„ì•¼ì˜ ë³€í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤." ë“± ì „ë¬¸ê°€ì  ê²¬í•´ ì„œìˆ .

        3. **ì£¼ì˜ì‚¬í•­**:
           - **ì–¸ì–´**: ë¬´ì¡°ê±´ **í•œêµ­ì–´**ë¡œ ì¶œë ¥.
           - ê° ì„¹ì…˜ ì œëª© ë°”ë¡œ ë’¤ì—ëŠ” ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆì„ í•  ê²ƒ.
           - ë³¸ë¬¸ ë‚´ìš©ì€ ë§ˆí¬ë‹¤ìš´ ì ìš© ê°€ëŠ¥.
        """
        
        # Dry Run ëª¨ë“œ ì²´í¬ (GitHub Actions Input)
        is_dry_run = os.getenv("DRY_RUN", "false").lower() == "true"
        
        if is_dry_run:
            logger.info("ğŸ§ª [Dry Run Mode] AI API í˜¸ì¶œì„ ê±´ë„ˆë›°ê³  ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            return """
**[Dry Run] í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ìƒì„±ëœ ìƒ˜í”Œ ì½˜í…ì¸ ì…ë‹ˆë‹¤.**

Key Facts
* ì´ ê²Œì‹œë¬¼ì€ ë””ìì¸ ë° ë ˆì´ì•„ì›ƒ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (AI ìš”ì•½ ë¯¸ì‚¬ìš©)
* ì‹¤ì œ Gemini APIë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ í¬ë ˆë”§ì´ ì†Œì§„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
* Pexels ì´ë¯¸ì§€ëŠ” ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì–´ ë””ìì¸ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Analyst's Insight
ì´ ì„¹ì…˜ì€ Analystì˜ í†µì°°ë ¥ì´ ë“¤ì–´ê°€ëŠ” ê³µê°„ì…ë‹ˆë‹¤. í°íŠ¸ í¬ê¸°, ì¤„ ê°„ê²©, ë°•ìŠ¤ ë””ìì¸(Callout)ì´ ì œëŒ€ë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. 
ì„±ê³µì ì¸ íˆ¬ìë¥¼ ìœ„í•´ì„œëŠ” ë„êµ¬ì˜ íš¨ìœ¨ì„±ì„ ì ê²€í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì´ í…ŒìŠ¤íŠ¸ ê²Œì‹œë¬¼ì´ ë³´ì¸ë‹¤ë©´, ë´‡ì˜ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•˜ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.
"""
        
        for model_name in self.model_candidates:
            try:
                logger.info(f"ğŸ¤– ëª¨ë¸ ì‹œë„ ì¤‘: {model_name}")
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                logger.warning(f"âš ï¸ {model_name} ìƒì„± ì‹¤íŒ¨ (ë‹¤ìŒ ëª¨ë¸ ì‹œë„): {e}")
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
        return f"ëª¨ë“  AI ëª¨ë¸ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì›ë¬¸ ë§í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n\nì›ë¬¸: {news_item['link']}"

    def create_hugo_post(self, title, content, link, category, keyword):
        """Hugo í˜¸í™˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± (ìë™ ë¶„ë¥˜ ë° ë””ìì¸ ì ìš©)"""
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
        date_str = now.isoformat()
        filename_date = now.strftime("%Y-%m-%d-%H%M%S")
        
        # ëŒ€í‘œ ì´ë¯¸ì§€ URL ìƒì„± ì „ëµ
        primary_keyword = keyword.split()[0] if keyword else "business"
        
        # ì´ë¯¸ì§€ ì •ë³´ ì´ˆê¸°í™”
        image_url = ""
        image_alt = "Economics and Technology News"
        image_credit = ""

        if self.pexels_api_key:
            # Pexels API ì‚¬ìš© (í‚¤ì›Œë“œ ë§¤ì¹­ + ìƒì—…ì  ë¬´ë£Œ)
            headers = {"Authorization": self.pexels_api_key}
            try:
                # ê²€ìƒ‰ì–´ ê°œì„ : ì „ì²´ í‚¤ì›Œë“œ ì‚¬ìš© & ê²°ê³¼ 15ê°œ ì¤‘ ëœë¤ ì„ íƒ
                search_query = urllib.parse.quote(keyword if keyword else "technology")
                search_url = f"https://api.pexels.com/v1/search?query={search_query}&per_page=15"
                r = requests.get(search_url, headers=headers, timeout=10)
                r.raise_for_status()
                data = r.json()
                if data['photos']:
                    import random
                    photo = random.choice(data['photos']) # ğŸ² ëœë¤ ì„ íƒìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€
                    # WebP ë³€í™˜ ë° ì‚¬ì´ì¦ˆ ìµœì í™” (Perplexity ì¡°ì–¸ ë°˜ì˜)
                    # original ëŒ€ì‹  large2x ì‚¬ìš© + fm=webp íŒŒë¼ë¯¸í„° ì¶”ê°€
                    image_url = photo['src']['large2x'] + "?auto=compress&cs=tinysrgb&w=800&fm=webp"
                    image_alt = photo.get('alt', f"{keyword} related image")
                    photographer = photo.get('photographer', 'Pexels User')
                    photographer_url = photo.get('photographer_url', 'https://www.pexels.com')
                    image_credit = f"Photo by [{photographer}]({photographer_url}) on [Pexels](https://www.pexels.com)"
                else:
                    image_url = f"https://picsum.photos/seed/{filename_date}/800/600.webp"
                    image_credit = "Photo from Picsum Photos"
            except Exception as e:
                logger.warning(f"âš ï¸ Pexels API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                image_url = f"https://picsum.photos/seed/{filename_date}/800/600"
                image_credit = "Photo from Picsum Photos"
        else:
            # ê¸°ë³¸ Picsum ì‚¬ìš© (100% ì•ˆì „í•˜ì§€ë§Œ ëœë¤)
            image_url = f"https://picsum.photos/seed/{filename_date}/800/600"
            image_credit = "Photo from Picsum Photos"

        # íŒŒì¼ëª… ìƒì„±
        safe_filename = f"news-{category}-{filename_date}.md"
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ì†Œë¬¸ì í´ë”ëª… ì‚¬ìš©)
        folder_map = {
            "Money": "money",
            "Tools": "tools"
        }
        folder_name = folder_map.get(category, "posts")

        # ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸ êµ¬ì„±
        lines = content.strip().split('\n')
        extracted_title = title 
        body_content = content

        if lines and not lines[0].startswith('#'):
             extracted_title = lines[0].replace('ì œëª©:', '').strip()
             body_content = '\n'.join(lines[1:]).strip()

        # HTML Callout ë°•ìŠ¤ ì ìš©ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì¹˜í™˜ (í”„ë¡¬í”„íŠ¸ì—ì„œ ìœ ë„í•˜ì§€ë§Œ í•œë²ˆ ë” ì •ì œ)
        # Key Facts ì„¹ì…˜ (ëª¨ë¸ì´ 'Key Facts'ë§Œ ì¶œë ¥í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë§¤ì¹­ ë¬¸ìì—´ ì¶•ì†Œ)
        body_content = body_content.replace("Key Facts", "<div class='callout callout-key-facts'>\n<span class='callout-title'>Key Facts</span>")
        # Analyst's Insight ì„¹ì…˜ (ëë‚˜ëŠ” ì§€ì  íŒŒì•…ì´ ì–´ë ¤ìš°ë¯€ë¡œ div ë‹«ëŠ” íƒœê·¸ ì‚½ì… ì „ëµ)
        if "Analyst's Insight" in body_content:
            body_content = body_content.replace("<div class='callout callout-key-facts'>", "<div class='callout callout-key-facts'>") # ìœ ì§€
            # Key Facts ë‹«ê³  Insight ì—´ê¸°
            body_content = body_content.replace("Analyst's Insight", "</div>\n\n<div class='callout callout-insight'>\n<span class='callout-title'>Analyst's Insight</span>")
            body_content += "\n</div>" # ë§ˆì§€ë§‰ ë‹«ê¸°
        else:
            body_content = body_content.replace("</div>", "</div>") # ì•ˆì „ì¥ì¹˜

        markdown = f"""---
title: "{extracted_title}"
date: {date_str}
draft: false
categories: ["{category}"]
tags: ["{category}", "Market Insight", "Analysis"]
---

![{image_alt}]({image_url})
*<small>{image_credit}</small>*

{body_content}

---
*â€» ë³¸ ë¶„ì„ì€ ê¸€ë¡œë²Œ ì‹œì¥ ë‰´ìŠ¤ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, íˆ¬ì ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤. ëª¨ë“  íˆ¬ìì˜ ì±…ì„ì€ íˆ¬ìì ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.*

*ì›ë¬¸ ë§í¬: <a href="{link}" target="_blank" rel="noopener noreferrer">ë³´ëŸ¬ê°€ê¸°</a>*
"""
        return safe_filename, markdown, folder_name

    def push_to_github(self, filename, content, folder_name, commit_message):
        """GitHub ì €ì¥ì†Œì— íŒŒì¼ ì—…ë¡œë“œ"""
        if not self.repo:
            logger.info(f"ğŸš« GitHub ì €ì¥ì†Œ ë¯¸ì—°ê²°. ë¡œì»¬ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤. (íŒŒì¼ëª…: {filename})")
            safe_name = filename.replace("/", "_")
            with open(f"local_{safe_name}", "w", encoding="utf-8") as f:
                f.write(content)
            return False

        path = f"content/posts/{folder_name}/{filename}"
        
        try:
            # íŒŒì¼ ìƒì„±
            self.repo.create_file(path, commit_message, content, branch="main")
            logger.info(f"âœ… GitHub Push ì„±ê³µ: {path}")
            return True
        except GithubException as e:
            logger.error(f"âŒ GitHub Push ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ë¡œì»¬ì— ì €ì¥í•˜ì—¬ í™•ì¸ ê°€ëŠ¥í•˜ê²Œ í•¨
            safe_name = filename.replace("/", "_")
            with open(f"failed_push_{safe_name}", "w", encoding="utf-8") as f:
                f.write(content)
            # ğŸš¨ ì—ëŸ¬ë¥¼ ìˆ¨ê¸°ì§€ ì•Šê³  ë°œìƒì‹œì¼œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤íŒ¨(Red)ë¡œ ë§Œë“¦
            raise e

    def run(self):
        logger.info("ğŸš€ Tikkles Analyst Bot (v2.1 - Fixed Dependencies) ì‹œì‘")
        
        # ì‹œê°„ëŒ€ë³„ íƒ€ê²Ÿ ì„¤ì • (KST ê¸°ì¤€)
        kst = pytz.timezone('Asia/Seoul')
        current_hour = datetime.now(kst).hour
        
        # ì•„ì¹¨(07:50) -> 'Money' (ê²½ì œ/íˆ¬ì)
        # ì €ë…(18:50) -> 'Tools' (IT/í…Œí¬)
        if current_hour < 14: 
            logger.info(f"ğŸŒ… ì•„ì¹¨ ë£¨í‹´ ì‹¤í–‰ (í˜„ì¬ {current_hour}ì‹œ) - íƒ€ê²Ÿ: Money (ê²½ì œ)")
            target = {"keyword": "Economy Bitcoin Stock Market", "category": "Money"}
        else:
            logger.info(f"ğŸŒ† ì €ë… ë£¨í‹´ ì‹¤í–‰ (í˜„ì¬ {current_hour}ì‹œ) - íƒ€ê²Ÿ: Tools (IT)")
            target = {"keyword": "AI Technology Tools Gadgets", "category": "Tools"}

        keyword = target["keyword"]
        category = target["category"]
        
        # Dry Run ëª¨ë“œ ì²´í¬ (GitHub Actions Input)
        is_dry_run = os.getenv("DRY_RUN", "false").lower() == "true"

        if is_dry_run:
            logger.info("ğŸ§ª [Dry Run Mode] RSS ìˆ˜ì§‘ì„ ìƒëµí•˜ê³  í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë‰´ìŠ¤ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            news_list = [{
                'title': '[Test] Global Market Insight Visualization Sample',
                'link': 'https://rohbomb.github.io',
                'summary': 'This is a test summary for design verification. It triggers the Dry Run logic.',
                'keyword': keyword
            }]
        else:
            news_list = self.fetch_news(keyword)
            # ğŸš¨ ë‰´ìŠ¤ ì—†ìŒ = ë´‡ ì‹¤íŒ¨ë¡œ ê°„ì£¼ (GitHub Actions Red Light)
            if not news_list:
                logger.error(f"âŒ '{keyword}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ë¯¸êµ­ êµ¬ê¸€ ë‰´ìŠ¤ ê¸°ì¤€)")
                import sys
                sys.exit(1)
        
        success_count = 0
        for news in news_list:
            logger.info(f"ğŸ” ë¶„ì„ ì¤‘: {news['title']}")
            blog_content = self.generate_content(news)
            
            # ğŸš¨ AI ìƒì„± ì‹¤íŒ¨ ì‹œ(ì¿¼í„° ì´ˆê³¼ ë“±) ì“°ë ˆê¸° ê²Œì‹œë¬¼ ìƒì„± ë°©ì§€
            if "AI ìš”ì•½ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in blog_content or "ëª¨ë“  AI ëª¨ë¸ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" in blog_content:
                logger.error(f"â›” ê²Œì‹œë¬¼ ìƒì„± ì¤‘ë‹¨: AI ì‘ë‹µ ì‹¤íŒ¨ ({news['title']})")
                continue

            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì œëª© ë“±ì„ ì²´í¬í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ì‹œê°„ ê¸°ë°˜ íŒŒì¼ëª…ìœ¼ë¡œ íšŒí”¼
            filename, markdown, folder_name = self.create_hugo_post(news['title'], blog_content, news['link'], category, keyword)
            
            if self.push_to_github(filename, markdown, folder_name, f"Analyst Bot: {news['title']}"):
                success_count += 1
        
        if success_count == 0:
            logger.error("âŒ ìƒì„±ëœ ê²Œì‹œë¬¼ì´ 0ê°œì…ë‹ˆë‹¤. (AI ì‹¤íŒ¨ ë˜ëŠ” Push ì‹¤íŒ¨)")
            import sys
            sys.exit(1)
        else:
            logger.info(f"âœ… ì´ {success_count}ê°œì˜ ê²Œì‹œë¬¼ì´ ë°œí–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    bot = HybridBot()
    bot.run()
